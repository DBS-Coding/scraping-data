{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a6aac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtube_transcript_api\n",
      "  Downloading youtube_transcript_api-1.0.3-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from youtube_transcript_api) (0.7.1)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from youtube_transcript_api) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->youtube_transcript_api) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->youtube_transcript_api) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->youtube_transcript_api) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->youtube_transcript_api) (2024.8.30)\n",
      "Downloading youtube_transcript_api-1.0.3-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   -------------------------------------- - 2.1/2.2 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 11.1 MB/s eta 0:00:00\n",
      "Installing collected packages: youtube_transcript_api\n",
      "Successfully installed youtube_transcript_api-1.0.3\n"
     ]
    }
   ],
   "source": [
    "# First, install the necessary library\n",
    "!pip install youtube_transcript_api\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a4ff21",
   "metadata": {},
   "source": [
    "### METODE 1: YOUTUBE TRANSKRIP API TO TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09d421cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading YouTube audio: HTTP Error 400: Bad Request\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import os\n",
    "import re\n",
    "from pytube import YouTube\n",
    "import datetime\n",
    "\n",
    "def get_video_id(url):\n",
    "    \"\"\"Extract video ID from YouTube URL\"\"\"\n",
    "    video_id_match = re.search(r'(?:v=|\\/)([0-9A-Za-z_-]{11}).*', url)\n",
    "    if video_id_match:\n",
    "        return video_id_match.group(1)\n",
    "    return None\n",
    "\n",
    "def download_youtube_audio(url, output_path=\"audio\"):\n",
    "    \"\"\"Download audio from YouTube video\"\"\"\n",
    "    try:\n",
    "        # Create output directory if it doesn't exist\n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path)\n",
    "            \n",
    "        # Create YouTube object\n",
    "        yt = YouTube(url)\n",
    "        \n",
    "        # Get video details for file naming\n",
    "        video_id = get_video_id(url)\n",
    "        video_title = yt.title\n",
    "        safe_title = re.sub(r'[^\\w\\-_]', '_', video_title)\n",
    "        \n",
    "        print(f\"Downloading audio from: {video_title}\")\n",
    "        \n",
    "        # Get audio stream and download\n",
    "        audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "        output_file = audio_stream.download(output_path=output_path)\n",
    "        \n",
    "        # Rename to mp3\n",
    "        base, ext = os.path.splitext(output_file)\n",
    "        new_file = f\"{base}.mp3\"\n",
    "        os.rename(output_file, new_file)\n",
    "        \n",
    "        print(f\"Audio downloaded to: {new_file}\")\n",
    "        return new_file, safe_title\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading YouTube audio: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def transcribe_audio(audio_path, language=\"id\"):\n",
    "    \"\"\"Transcribe audio using OpenAI Whisper\"\"\"\n",
    "    try:\n",
    "        print(f\"Loading Whisper model...\")\n",
    "        model = whisper.load_model(\"medium\")  # You can change model size: tiny, base, small, medium, large\n",
    "        \n",
    "        print(f\"Transcribing audio... (this may take some time)\")\n",
    "        result = model.transcribe(audio_path, language=language)\n",
    "        \n",
    "        return result[\"text\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error transcribing audio: {e}\")\n",
    "        return None\n",
    "\n",
    "# Main process\n",
    "def process_youtube_speech(youtube_url, language=\"id\"):\n",
    "    \"\"\"Process YouTube video: download audio and transcribe\"\"\"\n",
    "    # Download audio\n",
    "    audio_file, video_title = download_youtube_audio(youtube_url)\n",
    "    \n",
    "    if not audio_file:\n",
    "        return\n",
    "    \n",
    "    # Transcribe audio\n",
    "    transcription = transcribe_audio(audio_file, language=language)\n",
    "    \n",
    "    if not transcription:\n",
    "        return\n",
    "    \n",
    "    # Save transcription to file\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_filename = f\"Soekarno_{timestamp}.txt\"\n",
    "    \n",
    "    with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Source: {youtube_url}\\n\")\n",
    "        f.write(f\"Title: {video_title}\\n\")\n",
    "        f.write(f\"Transcribed: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        f.write(transcription)\n",
    "    \n",
    "    print(f\"✓ Transcription complete! Saved to {output_filename}\")\n",
    "    print(\"\\nPreview:\")\n",
    "    print(transcription[:500] + \"...\" if len(transcription) > 500 else transcription)\n",
    "    \n",
    "    return output_filename\n",
    "\n",
    "# Example usage\n",
    "youtube_url = \"https://www.youtube.com/watch?v=N_Cp4KBrRZw\"  # Change to your Soekarno speech video\n",
    "process_youtube_speech(youtube_url, language=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2d0733",
   "metadata": {},
   "source": [
    "### METHOD 2: OPEN AI WHISPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99bcbcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-whisper in c:\\users\\user\\anaconda3\\lib\\site-packages (20240930)\n",
      "Requirement already satisfied: ffmpeg-python in c:\\users\\user\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: pytube in c:\\users\\user\\anaconda3\\lib\\site-packages (15.0.0)\n",
      "Requirement already satisfied: numba in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai-whisper) (0.60.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai-whisper) (1.26.4)\n",
      "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai-whisper) (2.6.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai-whisper) (4.66.5)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai-whisper) (10.3.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai-whisper) (0.9.0)\n",
      "Requirement already satisfied: future in c:\\users\\user\\anaconda3\\lib\\site-packages (from ffmpeg-python) (1.0.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from numba->openai-whisper) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch->openai-whisper) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm->openai-whisper) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.4.26)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch->openai-whisper) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "# Install all required packages\n",
    "!pip install openai-whisper ffmpeg-python pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09f6551d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yt-dlp\n",
      "  Downloading yt_dlp-2025.5.22-py3-none-any.whl.metadata (174 kB)\n",
      "Downloading yt_dlp-2025.5.22-py3-none-any.whl (3.3 MB)\n",
      "   ---------------------------------------- 0.0/3.3 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 2.1/3.3 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.3/3.3 MB 9.6 MB/s eta 0:00:00\n",
      "Installing collected packages: yt-dlp\n",
      "Successfully installed yt-dlp-2025.5.22\n"
     ]
    }
   ],
   "source": [
    "!pip install yt-dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "180bbfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg-python in c:\\users\\user\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: future in c:\\users\\user\\anaconda3\\lib\\site-packages (from ffmpeg-python) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Try to install FFmpeg via pip (simpler but may not always work)\n",
    "!pip install ffmpeg-python\n",
    "\n",
    "# Option 2: Try to install via conda if you're using Anaconda\n",
    "# !conda install -c conda-forge ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3653fef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with pytube: HTTP Error 400: Bad Request\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=bcIk9n6nRUo&ab_channel=HendriTeja\n",
      "[youtube] bcIk9n6nRUo: Downloading webpage\n",
      "[youtube] bcIk9n6nRUo: Downloading tv client config\n",
      "[youtube] bcIk9n6nRUo: Downloading tv player API JSON\n",
      "[youtube] bcIk9n6nRUo: Downloading ios player API JSON\n",
      "[youtube] bcIk9n6nRUo: Downloading m3u8 information\n",
      "[info] bcIk9n6nRUo: Downloading 1 format(s): 251\n",
      "[download] Destination: audio\\audio_bcIk9n6nRUo_20250523_220126.mp3\n",
      "[download] 100% of    2.25MiB in 00:00:00 at 4.43MiB/s   \n",
      "Audio downloaded to: audio/audio_bcIk9n6nRUo_20250523_220126.mp3\n",
      "Loading Whisper model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▋                              | 294M/1.42G [00:43<02:54, 7.01MiB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 137\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m    136\u001b[0m youtube_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.youtube.com/watch?v=bcIk9n6nRUo&ab_channel=HendriTeja\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Change to your Soekarno speech video\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m process_youtube_speech(youtube_url, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 114\u001b[0m, in \u001b[0;36mprocess_youtube_speech\u001b[1;34m(youtube_url, language)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Rest of the function remains the same\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Transcribe audio\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m transcription \u001b[38;5;241m=\u001b[39m transcribe_audio(audio_file, language\u001b[38;5;241m=\u001b[39mlanguage)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m transcription:\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 89\u001b[0m, in \u001b[0;36mtranscribe_audio\u001b[1;34m(audio_path, language)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading Whisper model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 89\u001b[0m     model \u001b[38;5;241m=\u001b[39m whisper\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedium\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# You can change model size: tiny, base, small, medium, large\u001b[39;00m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranscribing audio... (this may take some time)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     92\u001b[0m     result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtranscribe(audio_path, language\u001b[38;5;241m=\u001b[39mlanguage)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\whisper\\__init__.py:137\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, device, download_root, in_memory)\u001b[0m\n\u001b[0;32m    134\u001b[0m     download_root \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXDG_CACHE_HOME\u001b[39m\u001b[38;5;124m\"\u001b[39m, default), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhisper\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _MODELS:\n\u001b[1;32m--> 137\u001b[0m     checkpoint_file \u001b[38;5;241m=\u001b[39m _download(_MODELS[name], download_root, in_memory)\n\u001b[0;32m    138\u001b[0m     alignment_heads \u001b[38;5;241m=\u001b[39m _ALIGNMENT_HEADS[name]\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(name):\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\site-packages\\whisper\\__init__.py:82\u001b[0m, in \u001b[0;36m_download\u001b[1;34m(url, root, in_memory)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\n\u001b[0;32m     75\u001b[0m     total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(source\u001b[38;5;241m.\u001b[39minfo()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Length\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[0;32m     76\u001b[0m     ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m     unit_divisor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m,\n\u001b[0;32m     80\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m loop:\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 82\u001b[0m         buffer \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m8192\u001b[39m)\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m buffer:\n\u001b[0;32m     84\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\http\\client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\Lib\\ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import os\n",
    "import re\n",
    "from pytube import YouTube\n",
    "import datetime\n",
    "import yt_dlp\n",
    "\n",
    "def get_video_id(url):\n",
    "    \"\"\"Extract video ID from YouTube URL\"\"\"\n",
    "    video_id_match = re.search(r'(?:v=|\\/)([0-9A-Za-z_-]{11}).*', url)\n",
    "    if video_id_match:\n",
    "        return video_id_match.group(1)\n",
    "    return None\n",
    "\n",
    "\n",
    "def download_with_ytdlp(url, output_path=\"audio\", ffmpeg_location=None):\n",
    "    \"\"\"Alternative download using yt-dlp with ffmpeg handling\"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path)\n",
    "            \n",
    "        video_id = get_video_id(url)\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_file = f\"{output_path}/audio_{video_id}_{timestamp}.mp3\"\n",
    "        \n",
    "        ydl_opts = {\n",
    "            'format': 'bestaudio/best',\n",
    "            'outtmpl': output_file,\n",
    "            'quiet': False,\n",
    "            'no_warnings': False\n",
    "        }\n",
    "        \n",
    "        # Add ffmpeg location if provided\n",
    "        if ffmpeg_location:\n",
    "            ydl_opts['ffmpeg_location'] = ffmpeg_location\n",
    "            ydl_opts['postprocessors'] = [{\n",
    "                'key': 'FFmpegExtractAudio',\n",
    "                'preferredcodec': 'mp3',\n",
    "                'preferredquality': '192',\n",
    "            }]\n",
    "        \n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            info = ydl.extract_info(url, download=True)\n",
    "            video_title = info.get('title', f\"video_{video_id}\")\n",
    "            \n",
    "        print(f\"Audio downloaded to: {output_file}\")\n",
    "        return output_file, video_title\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading with yt-dlp: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def download_youtube_audio(url, output_path=\"audio\"):\n",
    "    \"\"\"Download audio from YouTube video using pytube\"\"\"\n",
    "    try:\n",
    "        # Create output directory if it doesn't exist\n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path)\n",
    "            \n",
    "        # Create YouTube object\n",
    "        yt = YouTube(url)\n",
    "        \n",
    "        # Get video details for file naming\n",
    "        video_id = get_video_id(url)\n",
    "        video_title = yt.title\n",
    "        safe_title = re.sub(r'[^\\w\\-_]', '_', video_title)\n",
    "        \n",
    "        print(f\"Downloading audio from: {video_title}\")\n",
    "        \n",
    "        # Get audio stream and download\n",
    "        audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "        output_file = audio_stream.download(output_path=output_path)\n",
    "        \n",
    "        # Rename to mp3\n",
    "        base, ext = os.path.splitext(output_file)\n",
    "        new_file = f\"{base}.mp3\"\n",
    "        os.rename(output_file, new_file)\n",
    "        \n",
    "        print(f\"Audio downloaded to: {new_file}\")\n",
    "        return new_file, safe_title\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with pytube: {e}\")\n",
    "        return None, None\n",
    "def transcribe_audio(audio_path, language=\"id\"):\n",
    "    \"\"\"Transcribe audio using OpenAI Whisper\"\"\"\n",
    "    try:\n",
    "        print(f\"Loading Whisper model...\")\n",
    "        model = whisper.load_model(\"medium\")  # You can change model size: tiny, base, small, medium, large\n",
    "        \n",
    "        print(f\"Transcribing audio... (this may take some time)\")\n",
    "        result = model.transcribe(audio_path, language=language)\n",
    "        \n",
    "        return result[\"text\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error transcribing audio: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_youtube_speech(youtube_url, language=\"id\"):\n",
    "    \"\"\"Process YouTube video: download audio and transcribe\"\"\"\n",
    "    # Try downloading with pytube first\n",
    "    audio_file, video_title = download_youtube_audio(youtube_url)\n",
    "    \n",
    "    # If pytube fails, try yt-dlp\n",
    "    if not audio_file:\n",
    "        audio_file, video_title = download_with_ytdlp(youtube_url)\n",
    "    \n",
    "    if not audio_file:\n",
    "        print(\"Failed to download audio using both methods.\")\n",
    "        return\n",
    "    \n",
    "    # Rest of the function remains the same\n",
    "    # Transcribe audio\n",
    "    transcription = transcribe_audio(audio_file, language=language)\n",
    "    \n",
    "    if not transcription:\n",
    "        return\n",
    "    \n",
    "    # Save transcription to file\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_filename = f\"Soekarno_{timestamp}.txt\"\n",
    "    \n",
    "    with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Source: {youtube_url}\\n\")\n",
    "        f.write(f\"Title: {video_title}\\n\")\n",
    "        f.write(f\"Transcribed: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        f.write(transcription)\n",
    "    \n",
    "    print(f\"✓ Transcription complete! Saved to {output_filename}\")\n",
    "    print(\"\\nPreview:\")\n",
    "    print(transcription[:500] + \"...\" if len(transcription) > 500 else transcription)\n",
    "    \n",
    "    return output_filename\n",
    "\n",
    "# Example usage\n",
    "youtube_url = \"https://www.youtube.com/watch?v=bcIk9n6nRUo&ab_channel=HendriTeja\"  # Change to your Soekarno speech video\n",
    "process_youtube_speech(youtube_url, language=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38448795",
   "metadata": {},
   "source": [
    "### Scrapping from Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08934947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berhasil mengumpulkan 25 kutipan:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kami menggoyangkan langit, menggempakan darat,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This country, the Republic of Indonesia, does ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bebek berjalan berbondong-bondong, akan tetapi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I hate imperialism. I detest colonialism. And ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Learning without thinking is useless, but thin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Quotes\n",
       "0  Kami menggoyangkan langit, menggempakan darat,...\n",
       "1  This country, the Republic of Indonesia, does ...\n",
       "2  Bebek berjalan berbondong-bondong, akan tetapi...\n",
       "3  I hate imperialism. I detest colonialism. And ...\n",
       "4  Learning without thinking is useless, but thin..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "# URL target\n",
    "url = \"https://www.goodreads.com/author/quotes/661589.Sukarno\"\n",
    "\n",
    "# User-Agent header untuk meniru browser\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "quotes_list = []\n",
    "\n",
    "while True:\n",
    "    # Mengirim permintaan HTTP\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    # Memeriksa status response\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Gagal mengakses halaman. Kode status: {response.status_code}\")\n",
    "        break\n",
    "        \n",
    "    # Parsing konten HTML\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Mencari semua elemen kutipan\n",
    "    quotes = soup.find_all('div', class_='quoteText')\n",
    "    \n",
    "    # Mengekstrak teks kutipan\n",
    "    for quote in quotes:\n",
    "        text = quote.get_text(strip=True).split('―')[0]\n",
    "        text = text.replace('“', '').replace('”', '').strip()\n",
    "        quotes_list.append(text)\n",
    "    \n",
    "    # Mencari link halaman berikutnya\n",
    "    next_page = soup.find('a', class_='next_page')\n",
    "    \n",
    "    if not next_page:\n",
    "        break  # Tidak ada halaman berikutnya\n",
    "        \n",
    "    url = \"https://www.goodreads.com\" + next_page['href']\n",
    "    sleep(2)  # Jeda untuk menghormati server\n",
    "\n",
    "# Membuat DataFrame\n",
    "df = pd.DataFrame(quotes_list, columns=['Quotes'])\n",
    "\n",
    "# Menyimpan ke CSV\n",
    "df.to_csv('quotes_soekarno.csv', index=False)\n",
    "\n",
    "# Menampilkan hasil\n",
    "print(f\"Berhasil mengumpulkan {len(df)} kutipan:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2b28ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to c:\\PythonVSCenv\\Capstone\\scrapping\\output2\\content_author_quotes.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "base_path = r\"c:\\PythonVSCenv\\Capstone\\scrapping\\output\"\n",
    "csv_path = r\"c:\\PythonVSCenv\\Capstone\\scrapping\"\n",
    "hatta_csv = os.path.join(csv_path, \"quotes_hatta.csv\")\n",
    "soekarno_csv = os.path.join(csv_path, \"quotes_soekarno.csv\")\n",
    "output_json = os.path.join(base_path, \"content_author_quotes.json\")\n",
    "\n",
    "def load_quotes(path):\n",
    "    if not os.path.exists(path):\n",
    "        return []\n",
    "    df = pd.read_csv(path)\n",
    "    col = 'Quotes' if 'Quotes' in df.columns else df.columns[0]\n",
    "    return [q.strip().strip('\"') for q in df[col].dropna().astype(str) if q.strip()]\n",
    "\n",
    "tags = [\n",
    "    'greeting','whoami','nationalism','revolution','independence',\n",
    "    'unity','advice','international','struggle','goodbye'\n",
    "]\n",
    "\n",
    "keywords = {\n",
    "    'greeting': ['selamat pagi','halo','hai','salam'],\n",
    "    'whoami': ['aku adalah','saya adalah','identitas saya'],\n",
    "    'nationalism': ['bangsa','negara','nasional','tanah air'],\n",
    "    'revolution': ['revolusi','letusan','mengguncang','gempakan'],\n",
    "    'independence': ['merdeka','kemerdekaan','bebas','penjajahan','kolonialisme'],\n",
    "    'unity': ['persatuan','bersatu','kesatuan','gotong royong'],\n",
    "    'advice': ['nasihat','petuah','bijak','pelajaran','ingatlah'],\n",
    "    'international': ['internasional','dunia','global','antar bangsa'],\n",
    "    'struggle': ['perjuangan','pengorbanan','berjuang','tantangan'],\n",
    "    'goodbye': ['selamat tinggal','sampai jumpa','berpisah']\n",
    "}\n",
    "\n",
    "def categorize(quotes):\n",
    "    cat = {t: [] for t in tags}\n",
    "    for q in quotes:\n",
    "        ql = q.lower()\n",
    "        for t in tags:\n",
    "            for kw in keywords[t]:\n",
    "                if re.search(r'\\b'+re.escape(kw)+r'\\b', ql):\n",
    "                    cat[t].append(q)\n",
    "                    break\n",
    "    return cat\n",
    "\n",
    "def build_intents(cat):\n",
    "    out = []\n",
    "    for t, qs in cat.items():\n",
    "        if not qs: continue\n",
    "        inp = [\n",
    "            f\"berikan kutipan tentang {t}\",\n",
    "            f\"quotes mengenai {t}\",\n",
    "            f\"{t} quotes\"\n",
    "        ]\n",
    "        if t=='whoami': inp += [\"siapa kamu\",\"tentang dirimu\"]\n",
    "        if t=='greeting': inp += [\"apa kabar\",\"selamat pagi\"]\n",
    "        out.append({\"tag\": t, \"input\": inp, \"responses\": list(dict.fromkeys(qs))})\n",
    "    return out\n",
    "\n",
    "hatta = load_quotes(hatta_csv)\n",
    "soekarno = load_quotes(soekarno_csv)\n",
    "\n",
    "data = {\n",
    "    \"Hatta\": {\"intents\": build_intents(categorize(hatta))},\n",
    "    \"Soekarno\": {\"intents\": build_intents(categorize(soekarno))}\n",
    "}\n",
    "\n",
    "with open(output_json, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Saved to\", output_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d19044d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to c:\\PythonVSCenv\\Capstone\\scrapping\\output2\\content_by_author_and_tags.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "base_path = r\"c:\\PythonVSCenv\\Capstone\\scrapping\\output2\"\n",
    "csv_path = r\"c:\\PythonVSCenv\\Capstone\\scrapping\"\n",
    "hatta_csv = os.path.join(csv_path, \"quotes_hatta.csv\")\n",
    "soekarno_csv = os.path.join(csv_path, \"quotes_soekarno.csv\")\n",
    "output_json = os.path.join(base_path, \"content_by_author_and_tags.json\")\n",
    "\n",
    "def load_quotes(path):\n",
    "    if not os.path.exists(path):\n",
    "        return []\n",
    "    df = pd.read_csv(path)\n",
    "    col = 'Quotes' if 'Quotes' in df.columns else df.columns[0]\n",
    "    return [q.strip().strip('\"') for q in df[col].dropna().astype(str) if q.strip()]\n",
    "\n",
    "tags = [\n",
    "    'greeting','whoami','nationalism','revolution','independence',\n",
    "    'unity','advice','international','struggle','goodbye'\n",
    "]\n",
    "\n",
    "keywords = {\n",
    "    'greeting': ['selamat pagi','halo','hai','salam'],\n",
    "    'whoami': ['aku adalah','saya adalah','identitas saya'],\n",
    "    'nationalism': ['bangsa','negara','nasional','tanah air'],\n",
    "    'revolution': ['revolusi','letusan','mengguncang','gempakan'],\n",
    "    'independence': ['merdeka','kemerdekaan','bebas','penjajahan','kolonialisme'],\n",
    "    'unity': ['persatuan','bersatu','kesatuan','gotong royong'],\n",
    "    'advice': ['nasihat','petuah','bijak','pelajaran','ingatlah'],\n",
    "    'international': ['internasional','dunia','global','antar bangsa'],\n",
    "    'struggle': ['perjuangan','pengorbanan','berjuang','tantangan'],\n",
    "    'goodbye': ['selamat tinggal','sampai jumpa','berpisah']\n",
    "}\n",
    "\n",
    "def categorize(quotes):\n",
    "    cat = {t: [] for t in tags}\n",
    "    for q in quotes:\n",
    "        ql = q.lower()\n",
    "        for t in tags:\n",
    "            for kw in keywords[t]:\n",
    "                if re.search(r'\\b'+re.escape(kw)+r'\\b', ql):\n",
    "                    cat[t].append(q)\n",
    "                    break\n",
    "    return cat\n",
    "\n",
    "def build_intents(cat):\n",
    "    out = []\n",
    "    for t, qs in cat.items():\n",
    "        if not qs: continue\n",
    "        inp = [\n",
    "            f\"berikan kutipan tentang {t}\",\n",
    "            f\"quotes mengenai {t}\",\n",
    "            f\"{t} quotes\"\n",
    "        ]\n",
    "        if t=='whoami': inp += [\"siapa kamu\",\"tentang dirimu\"]\n",
    "        if t=='greeting': inp += [\"apa kabar\",\"selamat pagi\"]\n",
    "        out.append({\"tag\": t, \"input\": inp, \"responses\": list(dict.fromkeys(qs))})\n",
    "    return out\n",
    "\n",
    "hatta = load_quotes(hatta_csv)\n",
    "soekarno = load_quotes(soekarno_csv)\n",
    "\n",
    "data = {\n",
    "    \"Hatta\": {\"intents\": build_intents(categorize(hatta))},\n",
    "    \"Soekarno\": {\"intents\": build_intents(categorize(soekarno))}\n",
    "}\n",
    "\n",
    "with open(output_json, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Saved to\", output_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a9ed18",
   "metadata": {},
   "source": [
    "Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd62d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Hatta quotes...\n",
      "Processing Soekarno quotes...\n",
      "✅ Files created: content_hatta.json & content_soekarno.json\n",
      "📊 Hatta: 17 quotes → 3 intents\n",
      "📊 Soekarno: 25 quotes → 4 intents\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Path configuration\n",
    "base_path = r\"c:\\PythonVSCenv\\Capstone\\scrapping\\output\"\n",
    "csv_path = r\"c:\\PythonVSCenv\\Capstone\\scrapping\"\n",
    "\n",
    "# Output files\n",
    "hatta_output = os.path.join(base_path, \"content_hatta.json\")\n",
    "soekarno_output = os.path.join(base_path, \"content_soekarno.json\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "# Tags and keywords\n",
    "tags = ['greeting','whoami','nationalism','revolution','independence',\n",
    "        'unity','advice','international','struggle','goodbye']\n",
    "\n",
    "keywords = {\n",
    "    'nationalism': ['bangsa','negara','nasional','tanah air'],\n",
    "    'revolution': ['revolusi','letusan','mengguncang','gempakan'],\n",
    "    'independence': ['merdeka','kemerdekaan','bebas','penjajahan'],\n",
    "    'struggle': ['perjuangan','pengorbanan','berjuang','tantangan']\n",
    "    # ... other keywords\n",
    "}\n",
    "\n",
    "# ================= PROCESS HATTA =================\n",
    "print(\"Processing Hatta quotes...\")\n",
    "\n",
    "# Load Hatta CSV\n",
    "df = pd.read_csv(os.path.join(csv_path, \"quotes_hatta.csv\"))\n",
    "hatta_quotes = [q.strip().strip('\"') for q in df['Quotes'].dropna().astype(str)]\n",
    "\n",
    "# Categorize Hatta quotes\n",
    "hatta_categories = {t: [] for t in tags}\n",
    "for q in hatta_quotes:\n",
    "    ql = q.lower()\n",
    "    for t in tags:\n",
    "        for kw in keywords.get(t, []):\n",
    "            if re.search(r'\\b'+re.escape(kw)+r'\\b', ql):\n",
    "                hatta_categories[t].append(q)\n",
    "                break\n",
    "\n",
    "# Build Hatta intents\n",
    "hatta_intents = []\n",
    "for t, qs in hatta_categories.items():\n",
    "    if qs:\n",
    "        intent = {\n",
    "            \"tag\": t,\n",
    "            \"input\": [f\"kutipan {t}\", f\"quotes {t}\"],\n",
    "            \"responses\": list(dict.fromkeys(qs))\n",
    "        }\n",
    "        hatta_intents.append(intent)\n",
    "\n",
    "# Save Hatta JSON\n",
    "hatta_data = {\"author\": \"Hatta\", \"intents\": hatta_intents}\n",
    "with open(hatta_output, 'w', encoding='utf-8') as f:\n",
    "    json.dump(hatta_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# ================= PROCESS SOEKARNO =================\n",
    "print(\"Processing Soekarno quotes...\")\n",
    "\n",
    "# Load Soekarno CSV\n",
    "df = pd.read_csv(os.path.join(csv_path, \"quotes_soekarno.csv\"))\n",
    "soekarno_quotes = [q.strip().strip('\"') for q in df['Quotes'].dropna().astype(str)]\n",
    "\n",
    "# Categorize Soekarno quotes\n",
    "soekarno_categories = {t: [] for t in tags}\n",
    "for q in soekarno_quotes:\n",
    "    ql = q.lower()\n",
    "    for t in tags:\n",
    "        for kw in keywords.get(t, []):\n",
    "            if re.search(r'\\b'+re.escape(kw)+r'\\b', ql):\n",
    "                soekarno_categories[t].append(q)\n",
    "                break\n",
    "\n",
    "# Build Soekarno intents\n",
    "soekarno_intents = []\n",
    "for t, qs in soekarno_categories.items():\n",
    "    if qs:\n",
    "        intent = {\n",
    "            \"tag\": t,\n",
    "            \"input\": [f\"kutipan {t}\", f\"quotes {t}\"],\n",
    "            \"responses\": list(dict.fromkeys(qs))\n",
    "        }\n",
    "        soekarno_intents.append(intent)\n",
    "\n",
    "# Save Soekarno JSON\n",
    "soekarno_data = {\"author\": \"Soekarno\", \"intents\": soekarno_intents}\n",
    "with open(soekarno_output, 'w', encoding='utf-8') as f:\n",
    "    json.dump(soekarno_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"✅ Files created: content_hatta.json & content_soekarno.json\")\n",
    "print(f\"📊 Hatta: {len(hatta_quotes)} quotes → {len(hatta_intents)} intents\")\n",
    "print(f\"📊 Soekarno: {len(soekarno_quotes)} quotes → {len(soekarno_intents)} intents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eb0466",
   "metadata": {},
   "source": [
    "#### Melakukan pergantian format ke json untuk quotes quotes content json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171c5c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berhasil mengonversi kutipan ke JSON: c:\\PythonVSCenv\\Capstone\\scrapping\\content.json\n",
      "Peringatan: File tidak ditemukan - c:\\PythonVSCenv\\Capstone\\scrapping\\output2\\quotes_hatta.csv\n",
      "Peringatan: File tidak ditemukan - c:\\PythonVSCenv\\Capstone\\scrapping\\output2\\quotes_soekarno.csv\n",
      "Tidak ada kutipan yang dimuat dari c:\\PythonVSCenv\\Capstone\\scrapping\\output2\\quotes_hatta.csv\n",
      "Tidak ada kutipan yang dimuat dari c:\\PythonVSCenv\\Capstone\\scrapping\\output2\\quotes_soekarno.csv. Pastikan file tersebut ada dan formatnya benar.\n",
      "Berhasil mengonversi kutipan ke JSON: c:\\PythonVSCenv\\Capstone\\scrapping\\output2\\content.json\n",
      "Peringatan: File JSON yang dihasilkan kosong karena tidak ada kutipan yang ditemukan.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Define base path for the files\n",
    "base_path = r\"c:\\PythonVSCenv\\Capstone\\scrapping\"\n",
    "\n",
    "# Define input CSV file names and output JSON file name\n",
    "hatta_csv_file = 'quotes_hatta.csv'\n",
    "soekarno_csv_file = 'quotes_soekarno.csv' # Pastikan file ini ada\n",
    "output_json_file = 'content.json'\n",
    "\n",
    "# Construct full paths\n",
    "hatta_csv_path = os.path.join(base_path, hatta_csv_file)\n",
    "soekarno_csv_path = os.path.join(base_path, soekarno_csv_file)\n",
    "output_json_path = os.path.join(base_path, output_json_file)\n",
    "\n",
    "def load_quotes_from_csv(csv_path):\n",
    "    \"\"\"Reads quotes from a CSV file.\"\"\"\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"Peringatan: File tidak ditemukan - {csv_path}\")\n",
    "        return []\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        # Asumsikan kolom pertama berisi kutipan, atau kolom bernama 'Quotes'\n",
    "        if 'Quotes' in df.columns:\n",
    "            quotes = df['Quotes'].dropna().astype(str).tolist()\n",
    "        elif not df.empty:\n",
    "            quotes = df.iloc[:, 0].dropna().astype(str).tolist()\n",
    "        else:\n",
    "            quotes = []\n",
    "        \n",
    "        # Membersihkan kutipan dari tanda kutip ganda yang mungkin ada di awal/akhir dari CSV\n",
    "        cleaned_quotes = [q.strip('\"') for q in quotes]\n",
    "        return cleaned_quotes\n",
    "    except Exception as e:\n",
    "        print(f\"Error saat membaca {csv_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Load quotes\n",
    "hatta_quotes = load_quotes_from_csv(hatta_csv_path)\n",
    "soekarno_quotes = load_quotes_from_csv(soekarno_csv_path) # Pastikan file quotes_soekarno.csv ada\n",
    "\n",
    "# Initialize intents list\n",
    "intents_list = []\n",
    "\n",
    "# Create intent for Hatta's quotes\n",
    "if hatta_quotes:\n",
    "    hatta_intent = {\n",
    "        \"tag\": \"quote_hatta\",\n",
    "        \"input\": [\n",
    "            \"kutipan hatta\", \"quotes hatta\", \"kata bijak hatta\", \n",
    "            \"pemikiran hatta\", \"nasihat hatta\"\n",
    "        ],\n",
    "        \"responses\": hatta_quotes\n",
    "    }\n",
    "    intents_list.append(hatta_intent)\n",
    "else:\n",
    "    print(f\"Tidak ada kutipan yang dimuat dari {hatta_csv_path}\")\n",
    "\n",
    "# Create intent for Soekarno's quotes\n",
    "if soekarno_quotes:\n",
    "    soekarno_intent = {\n",
    "        \"tag\": \"quote_soekarno\",\n",
    "        \"input\": [\n",
    "            \"kutipan soekarno\", \"quotes soekarno\", \"kata bijak soekarno\", \n",
    "            \"pemikiran soekarno\", \"pidato soekarno\", \"nasihat soekarno\"\n",
    "        ],\n",
    "        \"responses\": soekarno_quotes\n",
    "    }\n",
    "    intents_list.append(soekarno_intent)\n",
    "else:\n",
    "    print(f\"Tidak ada kutipan yang dimuat dari {soekarno_csv_path}. Pastikan file tersebut ada dan formatnya benar.\")\n",
    "\n",
    "# Final JSON structure\n",
    "final_json_data = {\n",
    "    \"intents\": intents_list\n",
    "}\n",
    "\n",
    "# Write to JSON file\n",
    "try:\n",
    "    with open(output_json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(final_json_data, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"Berhasil mengonversi kutipan ke JSON: {output_json_path}\")\n",
    "    if not intents_list:\n",
    "        print(\"Peringatan: File JSON yang dihasilkan kosong karena tidak ada kutipan yang ditemukan.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saat menulis file JSON: {e}\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Define base path for the files\n",
    "base_path = r\"c:\\PythonVSCenv\\Capstone\\scrapping\\output\"\n",
    "\n",
    "# Define input CSV file names and output JSON file name\n",
    "hatta_csv_file = 'quotes_hatta.csv'\n",
    "soekarno_csv_file = 'quotes_soekarno.csv' # Pastikan file ini ada\n",
    "output_json_file = 'content.json'\n",
    "\n",
    "# Construct full paths\n",
    "hatta_csv_path = os.path.join(base_path, hatta_csv_file)\n",
    "soekarno_csv_path = os.path.join(base_path, soekarno_csv_file)\n",
    "output_json_path = os.path.join(base_path, output_json_file)\n",
    "\n",
    "def load_quotes_from_csv(csv_path):\n",
    "    \"\"\"Reads quotes from a CSV file.\"\"\"\n",
    "    if not os.path.exists(csv_path):\n",
    "        return []\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if 'Quotes' in df.columns:\n",
    "        quotes = df['Quotes'].dropna().astype(str).tolist()\n",
    "    cleaned_quotes = [q.strip('\"') for q in quotes]\n",
    "    return cleaned_quotes\n",
    "\n",
    "# Load quotes\n",
    "hatta_quotes = load_quotes_from_csv(hatta_csv_path)\n",
    "soekarno_quotes = load_quotes_from_csv(soekarno_csv_path) # Pastikan file quotes_soekarno.csv ada\n",
    "\n",
    "# Initialize intents list\n",
    "intents_list = []\n",
    "\n",
    "# Create intent for Hatta's quotes\n",
    "if hatta_quotes:\n",
    "    hatta_intent = {\n",
    "        \"tag\": \"quote_hatta\",\n",
    "        \"input\": [\n",
    "            \"kutipan hatta\", \"quotes hatta\", \"kata bijak hatta\", \n",
    "            \"pemikiran hatta\", \"nasihat hatta\"\n",
    "        ],\n",
    "        \"responses\": hatta_quotes\n",
    "    }\n",
    "    intents_list.append(hatta_intent)\n",
    "else:\n",
    "    print(f\"Tidak ada kutipan yang dimuat dari {hatta_csv_path}\")\n",
    "\n",
    "# Create intent for Soekarno's quotes\n",
    "if soekarno_quotes:\n",
    "    soekarno_intent = {\n",
    "        \"tag\": \"quote_soekarno\",\n",
    "        \"input\": [\n",
    "            \"kutipan soekarno\", \"quotes soekarno\", \"kata bijak soekarno\", \n",
    "            \"pemikiran soekarno\", \"pidato soekarno\", \"nasihat soekarno\"\n",
    "        ],\n",
    "        \"responses\": soekarno_quotes\n",
    "    }\n",
    "    intents_list.append(soekarno_intent)\n",
    "else:\n",
    "    print(f\"Tidak ada kutipan yang dimuat dari {soekarno_csv_path}. Pastikan file tersebut ada dan formatnya benar.\")\n",
    "\n",
    "# Final JSON structure\n",
    "final_json_data = {\n",
    "    \"intents\": intents_list\n",
    "}\n",
    "\n",
    "# Write to JSON file\n",
    "try:\n",
    "    with open(output_json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(final_json_data, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"Berhasil mengonversi kutipan ke JSON: {output_json_path}\")\n",
    "    if not intents_list:\n",
    "        print(\"Peringatan: File JSON yang dihasilkan kosong karena tidak ada kutipan yang ditemukan.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saat menulis file JSON: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce6e252",
   "metadata": {},
   "source": [
    "Versi Sederhana\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f782f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Ultra simple version - minimal code\n",
    "def quick_convert():\n",
    "    \"\"\"Convert CSV to JSON \"\"\"\n",
    "    \n",
    "    # Read both CSV files\n",
    "    try:\n",
    "        hatta = pd.read_csv(r\"c:\\PythonVSCenv\\Capstone\\scrapping\\quotes_hatta.csv\")['Quotes'].dropna().tolist()\n",
    "    except:\n",
    "        hatta = []\n",
    "    \n",
    "    try:\n",
    "        soekarno = pd.read_csv(r\"c:\\PythonVSCenv\\Capstone\\scrapping\\quotes_soekarno.csv\")['Quotes'].dropna().tolist()\n",
    "    except:\n",
    "        soekarno = []\n",
    "    \n",
    "    # Create JSON structure\n",
    "    data = {\n",
    "        \"intents\": [\n",
    "            {\n",
    "                \"tag\": \"quote_hatta\",\n",
    "                \"input\": [\"kutipan hatta\", \"quotes hatta\", \"kata bijak hatta\"],\n",
    "                \"responses\": [str(q).strip('\"') for q in hatta]\n",
    "            },\n",
    "            {\n",
    "                \"tag\": \"quote_soekarno\", \n",
    "                \"input\": [\"kutipan soekarno\", \"quotes soekarno\", \"kata bijak soekarno\"],\n",
    "                \"responses\": [str(q).strip('\"') for q in soekarno]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Save to JSON\n",
    "    with open(r\"c:\\PythonVSCenv\\Capstone\\scrapping\\content.json\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"✅ Converted! Hatta: {len(hatta)} quotes, Soekarno: {len(soekarno)} quotes\")\n",
    "\n",
    "# Run\n",
    "quick_convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836f3738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49c7e781",
   "metadata": {},
   "source": [
    "Library dipecah\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b472d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL target - halaman quotes Soekarno di Goodreads\n",
    "url = \"https://www.goodreads.com/author/quotes/661589.Sukarno\"\n",
    "\n",
    "# Header untuk meniru browser (menghindari blocking)\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "}\n",
    "\n",
    "quotes_list = []  # List untuk menyimpan semua kutipan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7770921",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Kirim request ke halaman\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    # Cek status response\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Gagal mengakses halaman. Status: {response.status_code}\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
